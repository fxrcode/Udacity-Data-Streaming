from pyspark.sql import SparkSession

# TO-DO: create a variable with the absolute path to the text file
# /home/workspace/walkthrough/exercises/starter/Test.txt

# TO-DO: create a Spark session

# TO-DO: set the log level to WARN

# TO-DO: using the Spark session variable, call the appropriate
# function referencing the text file path to read the text file 

# TO-DO: call the appropriate function to filter the data containing
# the letter 'a', and then count the rows that were found

# TO-DO: call the appropriate function to filter the data containing
# the letter 'b', and then count the rows that were found


# TO-DO: print the count for letter 'd' and letter 's'

# TO-DO: stop the spark application